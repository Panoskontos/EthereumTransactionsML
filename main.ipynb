{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6066ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               hash  nonce  \\\n",
      "0           0  0xa611438e5637c227e5080477b7180fc3d1c76710f2aa...     14   \n",
      "1           1  0xd5d2fe97f1fa4b772476e208f1e9a3441a0f54a020ac...      3   \n",
      "2           2  0xc93e15158aa51a4d9a93c3c153868c8c89f4545c3445...     19   \n",
      "3           3  0x454bc286bda9cf62a43730e465df8e76c23124d6dde7...     17   \n",
      "4           4  0xba053083f0752cd5f9a152105698dba490d5992b9839...    993   \n",
      "\n",
      "   transaction_index                                from_address  \\\n",
      "0                 41  0x506a48155c891c78c04bc0b70eb1d9b2361635e0   \n",
      "1                 59  0x544c7de319b72b557a0c1fafccf5202813f9f3f7   \n",
      "2                 76  0x1562c07b34b828cedaadda6959a0b1362103b7b4   \n",
      "3                 83  0x0afaec415159835aab6d56fbc6a22e1d60c76c45   \n",
      "4                 90  0x7bd8477901552199e8208f62875aa94fab2fffb3   \n",
      "\n",
      "                                   to_address         value     gas  \\\n",
      "0  0x7cc46cf6392ed9db45351a3f82eb2cc3b83da761  0.000000e+00  157911   \n",
      "1  0xf89d7b9c864f589bbf53a82105107622b35eaa40  1.708352e+15   21000   \n",
      "2  0x7dbfed48bddd2d4357f1f3c7dc45f5f85eb7100e  1.240000e+17   21000   \n",
      "3  0x6448d7a20ece8c57212ad52b362b5c9b4feac27d  3.300000e+17  176364   \n",
      "4  0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45  0.000000e+00  212432   \n",
      "\n",
      "     gas_price                                              input  ...  \\\n",
      "0  12618483129  0xa0712d68000000000000000000000000000000000000...  ...   \n",
      "1  12118483129                                                 0x  ...   \n",
      "2  11618483129                                                 0x  ...   \n",
      "3  11618483129  0x7649b957000000000000000000000000000000000000...  ...   \n",
      "4  11618483129  0x5ae401dc000000000000000000000000000000000000...  ...   \n",
      "\n",
      "   receipt_contract_address  receipt_root receipt_status  \\\n",
      "0                       NaN           NaN              1   \n",
      "1                       NaN           NaN              1   \n",
      "2                       NaN           NaN              1   \n",
      "3                       NaN           NaN              1   \n",
      "4                       NaN           NaN              1   \n",
      "\n",
      "             block_timestamp  block_number  \\\n",
      "0  2022-12-04 17:56:23+00:00      16113072   \n",
      "1  2022-12-04 17:56:23+00:00      16113072   \n",
      "2  2022-12-04 17:56:23+00:00      16113072   \n",
      "3  2022-12-04 17:56:23+00:00      16113072   \n",
      "4  2022-12-04 17:56:23+00:00      16113072   \n",
      "\n",
      "                                          block_hash  max_fee_per_gas  \\\n",
      "0  0x2dded46570b4cf879e0083e7f37a9169061075965dfd...     2.362667e+10   \n",
      "1  0x2dded46570b4cf879e0083e7f37a9169061075965dfd...     2.000000e+11   \n",
      "2  0x2dded46570b4cf879e0083e7f37a9169061075965dfd...     1.601040e+10   \n",
      "3  0x2dded46570b4cf879e0083e7f37a9169061075965dfd...     1.601040e+10   \n",
      "4  0x2dded46570b4cf879e0083e7f37a9169061075965dfd...     1.576050e+10   \n",
      "\n",
      "  max_priority_fee_per_gas  transaction_type  receipt_effective_gas_price  \n",
      "0             2.500000e+09                 2                  12618483129  \n",
      "1             2.000000e+09                 2                  12118483129  \n",
      "2             1.500000e+09                 2                  11618483129  \n",
      "3             1.500000e+09                 2                  11618483129  \n",
      "4             1.500000e+09                 2                  11618483129  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# test\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('eth_transactions.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579eae1b",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69724de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b3e11",
   "metadata": {},
   "source": [
    "# About our Data\n",
    "\n",
    "<p>\n",
    "Unnamed: 0: This is likely an index column from the original dataset. It doesn't carry any meaningful information for our analysis.\n",
    "\n",
    "hash: This is the unique identifier of the transaction.\n",
    "\n",
    "nonce: This is a value that can only be used once. It's used to prevent the same transaction from being processed more than once.\n",
    "\n",
    "transaction_index: This is the position of the transaction in the block.\n",
    "\n",
    "from_address: This is the address of the sender of the transaction.\n",
    "\n",
    "to_address: This is the address of the receiver of the transaction.\n",
    "\n",
    "value: This is the amount of Ether being transferred in the transaction.\n",
    "\n",
    "gas: This is the amount of \"gas\" provided for the transaction. Gas in Ethereum is the measure of computational effort.\n",
    "\n",
    "gas_price: This is the price of gas in Gwei (1 Gwei = 1e-9 Ether) set by the sender of the transaction.\n",
    "\n",
    "input: This is an optional data field that can be included in a transaction. It's used when the transaction is sent to a smart contract.\n",
    "\n",
    "receipt_cumulative_gas_used: This is the total amount of gas used in the block when this transaction was processed.\n",
    "\n",
    "receipt_gas_used: This is the amount of gas used by this particular transaction.\n",
    "\n",
    "receipt_contract_address: If the transaction was a contract creation, this is the address of the created contract.\n",
    "\n",
    "receipt_status: This is the status of the transaction - '1' means the transaction was successful, and '0' means it failed.\n",
    "\n",
    "block_hash: This is the unique identifier of the block that includes this transaction.\n",
    "\n",
    "block_number: This is the number of the block that includes this transaction.\n",
    "\n",
    "block_timestamp: This is the timestamp of when the block was mined.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dd9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31000325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a48a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5eca0e",
   "metadata": {},
   "source": [
    "Strong Positive Correlation:\n",
    "Values close to +1 imply a strong positive correlation. This means that as one variable increases, the other variable also increases. For example, a correlation of +0.8 or higher is typically considered strong.\n",
    "\n",
    "Strong Negative Correlation:\n",
    "Values close to -1 indicate a strong negative correlation. This means that as one variable increases, the other decreases. Similarly, a correlation of -0.8 or lower is often considered strong in the negative direction.\n",
    "No Correlation:\n",
    "\n",
    "A value close to 0 implies no correlation. This means there is no linear relationship between the two variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f060a",
   "metadata": {},
   "source": [
    "## Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f2e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Unnamed: 0','receipt_root']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c4d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values - Since the 'to_address' column has missing values, we fill them with a placeholder \n",
    "# (Ethereum transactions to a null address are typically contract creation transactions)\n",
    "df['to_address'] = df['to_address'].fillna('ContractCreation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1527d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle receipt_contract_address missing values\n",
    "df['receipt_contract_address'] = df['receipt_contract_address'].fillna('Unknown address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7384ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle max_priority_fee_per_gas missing values\n",
    "df['max_fee_per_gas'].fillna(df['max_fee_per_gas'].mean(), inplace=True)\n",
    "df['max_priority_fee_per_gas'].fillna(df['max_priority_fee_per_gas'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad864ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd792c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b66d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'block_timestamp' to datetime\n",
    "df['block_timestamp'] = pd.to_datetime(df['block_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc001672",
   "metadata": {},
   "source": [
    "### Transaction Flow Analysis: \n",
    "\n",
    "Using from_address and to_address, we can analyze transaction flows, identifying common senders and receivers, and understanding the network of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dc7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique addresses\n",
    "unique_from_addresses = df['from_address'].nunique()\n",
    "unique_to_addresses = df['to_address'].nunique()\n",
    "\n",
    "print(\"unique_from_addresses\",unique_from_addresses)\n",
    "print(\"unique_to_addresses\",unique_to_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1c124",
   "metadata": {},
   "source": [
    "# which addreses appear to sent more than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f567e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['from_address'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a67670",
   "metadata": {},
   "source": [
    "# Top 10 popular addresses to receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5abc5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['to_address'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be693128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "# import networkx as nx\n",
    "\n",
    "\n",
    "# top_5_senders = df['from_address'].value_counts().head(5).index\n",
    "# top_5_receivers = df['to_address'].value_counts().head(5).index\n",
    "\n",
    "# # Filtering the data to include only transactions involving these top addresses\n",
    "# simplified_data = df[(df['from_address'].isin(top_5_senders)) | (df['to_address'].isin(top_5_receivers))]\n",
    "\n",
    "# # Creating a simplified network graph\n",
    "# G_simplified = nx.DiGraph()\n",
    "\n",
    "# for _, row in simplified_data.iterrows():\n",
    "#     G_simplified.add_edge(row['from_address'], row['to_address'], weight=row['value'])\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# pos_simplified = nx.spring_layout(G_simplified, seed=42)  # for consistent layout\n",
    "# nx.draw_networkx(G_simplified, pos_simplified, node_size=700, node_color='lightblue', alpha=0.8, arrows=True)\n",
    "# plt.title('Simplified Transaction Flow Among Top Ethereum Addresses')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a7587",
   "metadata": {},
   "source": [
    "# When?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f22507",
   "metadata": {},
   "source": [
    "## Temporal Patterns: \n",
    "\n",
    "Here, we'll plot the number of transactions over time, looking for hourly or minute patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2d2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Patterns: Analyzing transaction counts by hour\n",
    "\n",
    "# Extracting hour from the timestamp\n",
    "df['hour'] = df['block_timestamp'].dt.hour\n",
    "\n",
    "# Grouping data by hour to count transactions\n",
    "transaction_counts_by_hour = df.groupby('hour').size()\n",
    "\n",
    "# Plotting the number of transactions per hour\n",
    "plt.figure(figsize=(12, 6))\n",
    "transaction_counts_by_hour.plot(kind='bar')\n",
    "plt.title('Number of Transactions Per Hour')\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b22820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Patterns: Analyzing transaction counts by minute\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Extracting hour from the timestamp\n",
    "# Extracting minute and hour from the timestamp for more granular analysis\n",
    "df['minute_of_hour'] = df['block_timestamp'].dt.minute\n",
    "df['hour_of_day'] = df['block_timestamp'].dt.hour\n",
    "\n",
    "# Combining date, hour, and minute for a unique time identifier\n",
    "df['date_hour_minute'] =  df['hour_of_day'].astype(str) + ':' + df['minute_of_hour'].astype(str)\n",
    "\n",
    "\n",
    "# Grouping data by hour to count transactions\n",
    "transaction_counts_by_hour = df.groupby('date_hour_minute').size()\n",
    "\n",
    "# Plotting the number of transactions per hour\n",
    "plt.figure(figsize=(12, 6))\n",
    "transaction_counts_by_hour.plot(kind='bar')\n",
    "plt.title('Number of Transactions Per minute')\n",
    "plt.xlabel('Minute of Hour (0-60)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "# Customizing the x-axis labels\n",
    "ax = plt.gca()  # Get the current Axes instance\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=30)) # Adjust 'nbins' as needed\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc871b76",
   "metadata": {},
   "source": [
    "## Gas and Transaction Efficiency: \n",
    "\n",
    "We can visualize the distribution of gas used and gas prices, as well as how they change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aacc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Gas Used\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['gas'], bins=50, kde=False)\n",
    "plt.title('Distribution of Gas Used in Transactions')\n",
    "plt.xlabel('Gas Used')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')  # Log scale due to wide range of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b53466",
   "metadata": {},
   "source": [
    "By visualizing the distribution of gas used in transactions, we can identify the typical range of gas consumption. This can help us understand the average complexity of transactions on the Ethereum network. Unusually high gas consumption may indicate complex smart contract interactions or inefficient transaction practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45d9d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing how Gas Used and Gas Prices change over time\n",
    "# For simplicity, we will use the average values per hour\n",
    "df['hour'] = df['block_timestamp'].dt.hour\n",
    "avg_gas_by_day = df.groupby('hour')['gas'].mean()\n",
    "avg_gas_price_by_day = df.groupby('hour')['gas_price'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_gas_by_day.plot(kind='line')\n",
    "plt.title('Average Gas Used Per Transaction Over Time By Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Gas Used')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_gas_price_by_day.plot(kind='line')\n",
    "plt.title('Average Gas Price Over Time By Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Gas Price (Gwei)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad401595",
   "metadata": {},
   "source": [
    "We can identify periods of congestion or low activity based on fluctuations in gas prices. High gas prices may indicate network congestion and increased demand for transaction processing, while low gas prices may suggest periods of low activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c04487",
   "metadata": {},
   "source": [
    "Correlation between Gas Price and Gas Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6de0c5",
   "metadata": {},
   "source": [
    "Analyzing the relationship between gas prices and gas used in transactions can help us understand user behavior and network dynamics. For example, we might observe that users are willing to pay higher gas prices for transactions with larger gas consumption, indicating a willingness to prioritize more complex or high-value transactions during periods of congestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "557c1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we will use the average values per minute\n",
    "\n",
    "# Extracting hour from the timestamp\n",
    "# Extracting minute and hour from the timestamp for more granular analysis\n",
    "df['minute_of_hour'] = df['block_timestamp'].dt.minute\n",
    "df['hour_of_day'] = df['block_timestamp'].dt.hour\n",
    "\n",
    "# Combining date, hour, and minute for a unique time identifier\n",
    "df['date_hour_minute'] =  df['hour_of_day'].astype(str) + ':' + df['minute_of_hour'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "avg_gas_by_day = df.groupby('date_hour_minute')['gas'].mean()\n",
    "avg_gas_price_by_day = df.groupby('date_hour_minute')['gas_price'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_gas_by_day.plot(kind='line')\n",
    "plt.title('Average Gas Used Per Transaction Over Time By Minute')\n",
    "plt.xlabel('Minute')\n",
    "plt.ylabel('Average Gas Used')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_gas_price_by_day.plot(kind='line')\n",
    "plt.title('Average Gas Price Over Time By Minute')\n",
    "plt.xlabel('Minute')\n",
    "plt.ylabel('Average Gas Price (Gwei)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b29ea",
   "metadata": {},
   "source": [
    "Average Gas Used Per Transaction by Minute:\n",
    "\n",
    "</br>\n",
    "\n",
    "This line chart shows the average gas used in transactions for each minute within an hour. While minute-to-minute variations might be more subtle, this chart can still highlight any short-term fluctuations in gas usage, potentially revealing finer-grained patterns or anomalies.\n",
    "\n",
    "Average Gas Price by Minute:\n",
    "\n",
    "</br>\n",
    "\n",
    "This chart illustrates the average gas price (in Gwei) for each minute within an hour. Like the gas usage, minute-level variations might be less pronounced but can still provide insights into very short-term pricing dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b550738",
   "metadata": {},
   "source": [
    "## Smart Contract Interactions: \n",
    "\n",
    "</br>\n",
    "We'll visualize the proportion of transactions that interact with smart contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa20b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Contract Interactions: Visualizing the proportion of transactions interacting with smart contracts\n",
    "\n",
    "# Identifying transactions with non-empty 'input' field as smart contract interactions\n",
    "df['is_smart_contract_interaction'] = df['input'].apply(lambda x: x != '0x')\n",
    "\n",
    "# Calculating the proportion of transactions that are smart contract interactions\n",
    "smart_contract_interaction_proportion = df['is_smart_contract_interaction'].mean()\n",
    "\n",
    "# Visualizing the proportion\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie([smart_contract_interaction_proportion, 1 - smart_contract_interaction_proportion], \n",
    "        labels=['Smart Contract Interactions', 'Other Transactions'], \n",
    "        autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgrey'])\n",
    "plt.title('Proportion of Transactions Interacting with Smart Contracts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840fd8f",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n",
    "Usage of Smart Contracts: The chart provides a clear view of how prevalent smart contract interactions are in the Ethereum network. A larger segment for smart contract interactions would indicate a significant use of Ethereum for more than just Ether transfers, highlighting its role as a platform for decentralized applications.\n",
    "\n",
    "Network Activity Composition: Understanding the proportion of smart contract interactions can give insights into the composition of network activity, which is crucial for both users and developers. It helps in gauging the network's complexity and the demand for computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc873856",
   "metadata": {},
   "source": [
    "## Contract Creation Activity: \n",
    "\n",
    "We can plot the number of new contracts created over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7055bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract Creation Activity: Plotting the number of new contracts created by minute\n",
    "df['is_contract_creation'] = df['receipt_contract_address'].notna()\n",
    "\n",
    "# Extracting minute and hour from the timestamp for more granular analysis\n",
    "df['minute_of_hour'] = df['block_timestamp'].dt.minute\n",
    "df['hour_of_day'] = df['block_timestamp'].dt.hour\n",
    "\n",
    "# Combining date, hour, and minute for a unique time identifier\n",
    "df['date_hour_minute'] =  df['hour_of_day'].astype(str) + ':' + df['minute_of_hour'].astype(str)\n",
    "\n",
    "# Grouping data by this unique time identifier to count new contract creations\n",
    "contract_creation_counts_minute = df.groupby('date_hour_minute')['is_contract_creation'].sum()\n",
    "\n",
    "# Plotting the number of new contracts created by minute\n",
    "# Note: This will be a large plot, so we'll limit it to a subset of the data\n",
    "sampled_contract_creation_counts_minute = contract_creation_counts_minute.head(1000)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sampled_contract_creation_counts_minute.plot(kind='line')\n",
    "plt.title('Number of New Contracts Created Over Time (By Minute)')\n",
    "plt.xlabel('Time (Date Hour:Minute)')\n",
    "plt.ylabel('Number of New Contracts Created')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99869ad4",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "Granular View of Contract Creation: Plotting the data by minute offers a granular view of contract creation activity. This can reveal short-term spikes or patterns that might be related to specific events or periods of high activity.\n",
    "\n",
    "High-Frequency Fluctuations: Unlike daily or hourly aggregations, minute-level data can exhibit more fluctuations, reflecting the immediacy of activities on the network.\n",
    "\n",
    "Potential for Anomaly Detection: This level of detail can be useful for detecting anomalies or unusual bursts of activity, which might be indicative of specific events or trends in the developer community.\n",
    "\n",
    "Limitations of Minute-Level Analysis: It's important to note that such fine-grained analysis may sometimes yield noisy data, making it challenging to discern clear trends. Additionally, the plot covers only a small portion of the entire dataset due to its size and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca3b61",
   "metadata": {},
   "source": [
    "## Transaction Success and Failures: \n",
    "\n",
    "The receipt_status column is crucial for understanding the reliability of the network. Analyzing the proportion of successful vs. failed transactions, and identifying patterns or common reasons for failures can be insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4885400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction Success and Failures: Visualizing the proportion of successful and failed transactions\n",
    "# Calculating the proportion of transaction statuses\n",
    "transaction_success_proportion = df['receipt_status'].value_counts(normalize=True)\n",
    "\n",
    "# Visualizing the proportion\n",
    "plt.figure(figsize=(8, 6))\n",
    "transaction_success_proportion.plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Proportion of Transaction Success vs. Failures')\n",
    "plt.xlabel('Status (1=Success, 0=Failure)')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a65922",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "Network Reliability: The chart provides a clear indication of the Ethereum network's reliability. A high proportion of successful transactions suggests a stable and reliable network.\n",
    "\n",
    "Impact of Network Conditions: The rate of failed transactions can be influenced by network conditions. For example, during times of high congestion or rapid changes in gas prices, the rate of failures might increase.\n",
    "\n",
    "User Experience: The ratio of successes to failures can also reflect the user experience. A lower rate of failures implies that users are generally able to execute their transactions without issues.\n",
    "\n",
    "Optimization Opportunities: For developers and network operators, understanding the proportion of failed transactions can help in identifying areas for optimization and improvement within the network or in user interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16083548",
   "metadata": {},
   "source": [
    "## Block-Level Analysis: \n",
    "\n",
    "We'll visualize the number of transactions per block and other related block-level metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6196fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block-Level Analysis: Visualizing the number of transactions per block and other related block-level metrics\n",
    "\n",
    "# Counting the number of transactions per block\n",
    "transactions_per_block = df.groupby('block_number').size()\n",
    "\n",
    "# Visualizing the number of transactions per block\n",
    "plt.figure(figsize=(12, 6))\n",
    "transactions_per_block.plot(kind='line')\n",
    "plt.title('Number of Transactions Per Block')\n",
    "plt.xlabel('Block Number')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculating additional block-level metrics such as average gas used and average gas price per block\n",
    "avg_gas_per_block = df.groupby('block_number')['gas'].mean()\n",
    "avg_gas_price_per_block = df.groupby('block_number')['gas_price'].mean()\n",
    "\n",
    "# Visualizing these metrics\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Average Gas Used Per Block\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_gas_per_block.plot(kind='line')\n",
    "plt.title('Average Gas Used Per Block')\n",
    "plt.xlabel('Block Number')\n",
    "plt.ylabel('Average Gas Used')\n",
    "\n",
    "# Average Gas Price Per Block\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_gas_price_per_block.plot(kind='line')\n",
    "plt.title('Average Gas Price Per Block (Gwei)')\n",
    "plt.xlabel('Block Number')\n",
    "plt.ylabel('Average Gas Price (Gwei)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91091a3",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "Block Utilization Trends: Understanding the number of transactions per block is crucial for assessing the Ethereum network's capacity and efficiency. It also helps in gauging the scalability of the network.\n",
    "\n",
    "Resource Usage Patterns: The average gas used per block reflects the network's resource usage patterns. Blocks consistently using high amounts of gas might indicate a need for optimization or scaling solutions.\n",
    "\n",
    "Gas Price Dynamics: The average gas price per block can provide insights into the economic aspects of the Ethereum network, particularly how users respond to changes in network demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62c134",
   "metadata": {},
   "source": [
    "# Which addresses have the highest average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50272cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average transaction value per sender address\n",
    "average_value_per_sender = df.groupby('from_address')['value'].mean()\n",
    "\n",
    "# Top 10 sender addresses with the highest average transaction value\n",
    "top_value_senders = average_value_per_sender.sort_values(ascending=False).head(10)\n",
    "\n",
    "(top_value_senders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04b2b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average transaction value per receiver address\n",
    "average_value_per_receiver = df.groupby('to_address')['value'].mean()\n",
    "# Top 10 receiver addresses with the highest average transaction value\n",
    "top_value_receivers = average_value_per_receiver.sort_values(ascending=False).head(10)\n",
    "(top_value_receivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "160933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for the 'value' column\n",
    "value_description = df['value'].describe()\n",
    "\n",
    "# Distribution of the transaction 'value'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['value'], bins=30, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Transaction Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "(value_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149af0",
   "metadata": {},
   "source": [
    "# For reference ethereum price was 3,510.33$ at the time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3b8e0",
   "metadata": {},
   "source": [
    "So 5.36 * 3,510.33 is approximately 18.815$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80387658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7781b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### The distribution of transaction values is highly skewed, with most transactions having low values. This is common in financial data, where a large number of transactions are for small amounts, and a small number of transactions are for large amounts.\n",
    "\n",
    "<br/>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc4a94",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "hour_of_day: This represents the hour of the day (in 24-hour format) when the block containing the transaction was added to the blockchain.\n",
    "\n",
    "day_of_week: This represents the day of the week (Monday=0, Sunday=6) when the block containing the transaction was added to the blockchain.\n",
    "\n",
    "month: This represents the months when the block containing the transaction was added to the blockchain.\n",
    "    \n",
    "year: This represents the hour of the year when the block containing the transaction was added to the blockchain.\n",
    "    \n",
    "total_transactions_sender: This represents the total number of transactions made by the sender address in the dataset.\n",
    "\n",
    "total_transactions_receiver: This represents the total number of transactions received by the receiver address in the dataset.\n",
    "\n",
    "average_value_sender: This represents the average value of transactions made by the sender address in the dataset.\n",
    "\n",
    "average_value_receiver: This represents the average value of transactions received by the receiver address in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4a86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df['hour_of_day'] = df['block_timestamp'].dt.hour\n",
    "df['minute'] = df['block_timestamp'].dt.minute\n",
    "df['day_of_week'] = df['block_timestamp'].dt.dayofweek\n",
    "df['month'] = df['block_timestamp'].dt.month\n",
    "df['year'] = df['block_timestamp'].dt.year\n",
    "\n",
    "# Total transactions made by each sender address\n",
    "total_transactions_sender = df.groupby('from_address').size()\n",
    "df['total_transactions_sender'] = df['from_address'].map(total_transactions_sender)\n",
    "\n",
    "# Total transactions received by each receiver address\n",
    "total_transactions_receiver = df.groupby('to_address').size()\n",
    "df['total_transactions_receiver'] = df['to_address'].map(total_transactions_receiver)\n",
    "\n",
    "# Average value of transactions made by each sender address\n",
    "average_value_sender = df.groupby('from_address')['value'].mean()\n",
    "df['average_value_sender'] = df['from_address'].map(average_value_sender)\n",
    "\n",
    "# Average value of transactions received by each receiver address\n",
    "average_value_receiver = df.groupby('to_address')['value'].mean()\n",
    "df['average_value_receiver'] = df['to_address'].map(average_value_receiver)\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb46916",
   "metadata": {},
   "source": [
    "### From Address Metrics ( Aggregation):\n",
    "\n",
    "Average Transaction Value: The mean value of Ether transferred in transactions for each address on each day.\n",
    "\n",
    "Average Gas Used: The mean amount of gas used in transactions for each address on each day.\n",
    "\n",
    "Average Gas Price: The mean price of gas (in Gwei) set by transactions for each address on each day.\n",
    "\n",
    "Total Transactions: The total number of transactions sent from each address on each day.\n",
    "\n",
    "Total Value Sent: The total amount of Ether sent from each address on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51df1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating by day for 'from_address'\n",
    "address_hour_agg = df.groupby(['from_address', 'date_hour_minute']).agg(\n",
    "    average_transaction_value=('value', 'mean'),\n",
    "    average_gas_used=('gas', 'mean'),\n",
    "    average_gas_price=('gas_price', 'mean'),\n",
    "    total_transactions=('hash', 'count'),\n",
    "    total_value_sent=('value', 'sum')\n",
    ")\n",
    "\n",
    "# Displaying the first few rows of the aggregated data\n",
    "address_hour_agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58bb042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder addresses for demonstration\n",
    "selected_addresses = ['0x21a31ee1afc51d94c2efccaa2092ad1028285549' ]  \n",
    "# Replace with actual addresses\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for address in selected_addresses:\n",
    "    # Filtering the data for the selected address\n",
    "    address_data = address_hour_agg.loc[address]\n",
    "\n",
    "    # Plotting average transaction value over time\n",
    "    plt.plot(address_data.index, address_data['average_transaction_value'], label=address)\n",
    "\n",
    "plt.xlabel('Date Hour Minute')\n",
    "plt.ylabel('Average Transaction Value')\n",
    "plt.title('Average Transaction Value Over Time for Selected Addresses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Customizing the x-axis labels\n",
    "ax = plt.gca()  # Get the current Axes instance\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=30)) # Adjust 'nbins' as needed\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaf69dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for address in selected_addresses:\n",
    "    # Filtering the data for the selected address\n",
    "    address_data = address_hour_agg.loc[address]\n",
    "\n",
    "    # Plotting average transaction value over time\n",
    "    plt.plot(address_data.index, address_data['average_gas_used'], label=address)\n",
    "\n",
    "plt.xlabel('Date Hour Minute')\n",
    "plt.ylabel('Average Gas Used')\n",
    "plt.title('Average Gas Used Over Time for Selected Addresses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Customizing the x-axis labels\n",
    "ax = plt.gca()  # Get the current Axes instance\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=30)) # Adjust 'nbins' as needed\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a28b209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for address in selected_addresses:\n",
    "    # Filtering the data for the selected address\n",
    "    address_data = address_hour_agg.loc[address]\n",
    "\n",
    "    # Plotting average transaction value over time\n",
    "    plt.plot(address_data.index, address_data['average_gas_price'], label=address)\n",
    "\n",
    "plt.xlabel('Date Hour Minute')\n",
    "plt.ylabel('Average Gas Price')\n",
    "plt.title('Average Gas Price Over Time for Selected Addresses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Customizing the x-axis labels\n",
    "ax = plt.gca()  # Get the current Axes instance\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=30)) # Adjust 'nbins' as needed\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5b576da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for address in selected_addresses:\n",
    "    # Filtering the data for the selected address\n",
    "    address_data = address_hour_agg.loc[address]\n",
    "\n",
    "    # Plotting average transaction value over time\n",
    "    plt.plot(address_data.index, address_data['total_transactions'], label=address)\n",
    "\n",
    "plt.xlabel('Date Hour Minute')\n",
    "plt.ylabel('Total Transactions')\n",
    "plt.title('Total Transactions Over Time for Selected Addresses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Customizing the x-axis labels\n",
    "ax = plt.gca()  # Get the current Axes instance\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=30)) # Adjust 'nbins' as needed\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073d1a4",
   "metadata": {},
   "source": [
    "Time series plots of transaction metrics can provide several insights useful for anomaly detection, especially when observing metrics like average transaction value, gas used, and gas prices over time. Here are some key insights you might derive:\n",
    "\n",
    "Sudden Spikes or Drops: Sharp increases or decreases in transaction values, gas used, or gas prices can indicate anomalous activity. For instance, a sudden spike in transaction value might suggest large transfers that are not typical for the address.\n",
    "\n",
    "Outliers: Points that deviate significantly from the general pattern could be potential outliers. These might be transactions that are unusually high or low compared to the normal activity of the address.\n",
    "\n",
    "Pattern Changes: Anomalies might be indicated by changes in the usual patterns of activity. For example, if an address consistently shows low transaction values and suddenly starts transacting in high values, it could be considered anomalous.\n",
    "\n",
    "Periodicity and Trends: Regular patterns like cyclical activity or trends (upward or downward) can be normal for some addresses. A break from these patterns could signal something unusual.\n",
    "\n",
    "Consistency with Known Events: If there are known market events or network changes (like Ethereum upgrades), see if the anomalies align with these events. Anomalies that coincide with such events might be explainable and not necessarily indicative of suspicious activity.\n",
    "\n",
    "Comparison Across Addresses: If you're observing multiple addresses, anomalies might also be identified by comparing their activities. An address behaving distinctly from others in a similar category could be flagged for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca3c22",
   "metadata": {},
   "source": [
    "## Pick an algorithm:\n",
    "\n",
    "- we will go with Isolation Forest or K-means or DBSCAN, ideally all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f9e93",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93f772",
   "metadata": {},
   "source": [
    "# K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8808dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame and the features are selected\n",
    "features = df[['hour_of_day', 'day_of_week', 'month', 'year', 'total_transactions_sender', 'total_transactions_receiver', 'average_value_sender', 'average_value_receiver']]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features.fillna(0))  # Handling nulls by replacing them with 0\n",
    "\n",
    "# Applying K-means\n",
    "kmeans = KMeans(n_clusters=5)  # Example with 5 clusters\n",
    "kmeans.fit(X_scaled)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Finding the distances of each point to its cluster center\n",
    "distances = np.min(cdist(X_scaled, kmeans.cluster_centers_, 'euclidean'), axis=1)\n",
    "\n",
    "# Marking the points which are significantly far away from the cluster centers as anomalies\n",
    "# You can define a threshold based on your understanding of the data\n",
    "threshold = np.percentile(distances, 95)  # Setting threshold as the 95th percentile for example\n",
    "anomalies = distances > threshold\n",
    "\n",
    "# Adding the anomaly labels to your DataFrame\n",
    "df['anomaly'] = anomalies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd52d85",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95716381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Isolation Forest\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Applying Isolation Forest\n",
    "# 5% of data as anomalies\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05)  \n",
    "iso_forest.fit(X_scaled)\n",
    "\n",
    "# Predicting anomalies (1 for normal, -1 for anomaly)\n",
    "anomalies_iso = iso_forest.predict(X_scaled)\n",
    "\n",
    "# Adding the anomaly labels to the DataFrame (True for anomalies, False for normal)\n",
    "df['anomaly_iso'] = anomalies_iso == -1\n",
    "\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ecd369",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Assuming 'df' is your DataFrame and the features are selected\n",
    "features = df[['hour_of_day', 'day_of_week', 'month', 'year', 'total_transactions_sender', 'total_transactions_receiver', 'average_value_sender', 'average_value_receiver']]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features.fillna(0))  # Handling nulls by replacing them with 0\n",
    "\n",
    "# Applying DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  \n",
    "dbscan.fit(X_scaled)\n",
    "\n",
    "# Extracting the cluster labels (-1 indicates outliers/anomalies)\n",
    "labels_dbscan = dbscan.labels_\n",
    "\n",
    "# Marking the outliers/anomalies\n",
    "anomalies_dbscan = labels_dbscan == -1\n",
    "\n",
    "# Adding the anomaly labels to your DataFrame\n",
    "df['anomaly_dbscan'] = anomalies_dbscan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b3ff4",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features['average_value_sender'], features['total_transactions_sender'], c=labels_dbscan, cmap='viridis', s=50, alpha=0.5)\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Average Value Sender')\n",
    "plt.ylabel('Total Transactions Sender')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the anomalies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features['average_value_sender'], features['total_transactions_sender'], c=anomalies_dbscan, cmap='coolwarm', s=50, alpha=0.5)\n",
    "plt.title('Anomalies Detected by DBSCAN')\n",
    "plt.xlabel('Average Value Sender')\n",
    "plt.ylabel('Total Transactions Sender')\n",
    "plt.colorbar(label='Anomaly')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5b522",
   "metadata": {},
   "source": [
    "n this example, the anomalies are defined as the points which are in the top 5% of distances from the cluster center. The choice of the threshold and the number of clusters (k) should be tailored to your specific dataset and the nature of the anomalies you expect to find."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8efa5",
   "metadata": {},
   "source": [
    "# Analyzing All Algotithm's Results\n",
    "# Columns where all agree are true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAlgorithmsAgreeAnomaly = df[(df['anomaly'] == True) & (df['anomaly_iso'] == True) & (df['anomaly_dbscan'] == True)][[\"anomaly_iso\",\"anomaly\",\"anomaly_dbscan\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAlgorithmsAgreeAnomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cbfab",
   "metadata": {},
   "source": [
    "# Columns where at least on of them is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atLeastOneisAnomaly = df[(df['anomaly'] == True) | (df['anomaly_iso'] == True) | (df['anomaly_dbscan'] == True)][[\"anomaly_iso\",\"anomaly\",\"anomaly_dbscan\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179536f6",
   "metadata": {},
   "source": [
    "# Columns where all agree that are normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ce3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['anomaly'] == False) & (df['anomaly_iso'] == False) & (df['anomaly_dbscan'] == False)][[\"anomaly_iso\",\"anomaly\",\"anomaly_dbscan\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting non-anomalous data\n",
    "sns.scatterplot(data=df[(df['anomaly'] == False) & \n",
    "                        (df['anomaly_iso'] == False) & \n",
    "                        (df['anomaly_dbscan'] == False)], \n",
    "                x='average_value_sender', \n",
    "                y='total_transactions_sender', \n",
    "                color='blue', \n",
    "                label='Normal')\n",
    "\n",
    "# Plotting anomalous data detected by all algorithms\n",
    "sns.scatterplot(data=df[(df['anomaly'] == True) & \n",
    "                        (df['anomaly_iso'] == True) & \n",
    "                        (df['anomaly_dbscan'] == True)], \n",
    "                x='average_value_sender', \n",
    "                y='total_transactions_sender', \n",
    "                color='red', \n",
    "                label='Anomaly (All Algorithms Agree)')\n",
    "\n",
    "# Anomalies where algorithms disagree\n",
    "# Plotting anomalies detected by any algorithm\n",
    "# sns.scatterplot(data=df[(df['anomaly'] != True) & \n",
    "#                         (df['anomaly_iso'] != True) & \n",
    "#                         (df['anomaly_dbscan'] != True)], \n",
    "#                 x='average_value_sender', \n",
    "#                 y='total_transactions_sender', \n",
    "#                 color='orange', \n",
    "#                 label='Anomaly (Disagreement)')\n",
    "\n",
    "plt.title('Anomalies in Ethereum Transactions')\n",
    "plt.xlabel('Average Value Sent by Sender')\n",
    "plt.ylabel('Total Transactions by Sender')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b5294",
   "metadata": {},
   "source": [
    "This visualization will help you quickly identify how anomalies differ in characteristics from normal data points. Remember to adjust the x and y-axis labels to match the features you're most interested in exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac531a",
   "metadata": {},
   "source": [
    "# Who are these addreses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_transactions = df[(df['anomaly'] == True) & \n",
    "                             (df['anomaly_iso'] == True) & \n",
    "                             (df['anomaly_dbscan'] == True)]\n",
    "\n",
    "sender_addresses = anomalous_transactions['from_address'].unique()\n",
    "receiver_addresses = anomalous_transactions['to_address'].unique()\n",
    "\n",
    "print(\"Anomalous sender addresses:\\n\", sender_addresses)\n",
    "print(\"\\n\")\n",
    "print(\"Anomalous receiver addresses:\\n\", receiver_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e5565",
   "metadata": {},
   "source": [
    "# Evaluation of the  Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e03489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame and the features are selected\n",
    "features = df[['hour_of_day', 'day_of_week', 'month', 'year', 'total_transactions_sender', 'total_transactions_receiver', 'average_value_sender', 'average_value_receiver']]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features.fillna(0))  # Handling nulls by replacing them with 0\n",
    "y = df['anomaly']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels_dbscan_test = dbscan.fit_predict(X_test)\n",
    "anomalies_dbscan_test = labels_dbscan_test == -1\n",
    "\n",
    "# Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05)\n",
    "anomalies_iso_test = iso_forest.fit_predict(X_test) == -1\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "anomalies_knn_test = knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"DBSCAN Classification Report:\")\n",
    "print(classification_report(y_test, anomalies_dbscan_test))\n",
    "\n",
    "print(\"Isolation Forest Classification Report:\")\n",
    "print(classification_report(y_test, anomalies_iso_test))\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, anomalies_knn_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bae77a",
   "metadata": {},
   "source": [
    "DBSCAN:\n",
    "\n",
    "DBSCAN achieves a high precision for anomaly detection, meaning that when it flags a transaction as anomalous, it's usually correct. However, it has a relatively low recall, indicating that it misses many true anomalies.\n",
    "The overall accuracy and f1-score are decent, but the low recall suggests that DBSCAN may not be capturing all anomalies effectively.\n",
    "\n",
    "Isolation Forest:\n",
    "\n",
    "Isolation Forest shows improvement over DBSCAN in terms of recall, capturing a higher proportion of true anomalies. However, its precision is moderate, indicating that some of the transactions flagged as anomalies may be false positives.\n",
    "The overall accuracy and f1-score are comparable to DBSCAN, but there's room for improvement, especially in precision and recall.\n",
    "\n",
    "KNN:\n",
    "\n",
    "KNN performs exceptionally well in all aspects, achieving high precision, recall, accuracy, and f1-score for anomaly detection.\n",
    "It shows almost perfect performance with very few false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc208ae7",
   "metadata": {},
   "source": [
    "Given these results, KNN appears to be the best-performing algorithm for this particular anomaly detection task. It provides the highest precision, recall, and overall accuracy among the three algorithms evaluated. If computational efficiency and interpretability are not significant concerns, KNN would be the preferred choice for anomaly detection in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe53b2d",
   "metadata": {},
   "source": [
    "# Let's visualise the best algorithms results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489baa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting non-anomalous data\n",
    "sns.scatterplot(data=df[(df['anomaly'] == False)], \n",
    "                x='average_value_sender', \n",
    "                y='total_transactions_sender', \n",
    "                color='blue', \n",
    "                label='Normal')\n",
    "\n",
    "# Plotting anomalous data detected by all algorithms\n",
    "sns.scatterplot(data=df[(df['anomaly'] == True)], \n",
    "                x='average_value_sender', \n",
    "                y='total_transactions_sender', \n",
    "                color='red', \n",
    "                label='Anomaly (KNN only)')\n",
    "\n",
    "plt.title('Anomalies in Ethereum Transactions')\n",
    "plt.xlabel('Average Value Sent by Sender')\n",
    "plt.ylabel('Total Transactions by Sender')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa01e2",
   "metadata": {},
   "source": [
    "# We can check addreses on etherscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554aa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anomalous receiver addresses:\\n\", receiver_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Data\n",
    "# df.to_csv(\"./eth_transactions_clustered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0349f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
